{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 8:  Exception Handling & Testing\n",
    "\n",
    "### Introduction\n",
    "\n",
    "This week's reading was Rother, K. (2017). <i>Exceptions in Python</i>. chapters 2, 3, 8, and 11.  When code does not behave as the programmer intended, it contains a defect or bug.  Defects can be inadvert such as a typo or incorrect syntax.  It also includes incorrect logic that would not result in an error message. The act of correcting the code is called debugging.  Automated testing are programs written to test another program.  It is considered a Best Practice.  Chapters 2 and 3 address defects.  Chapters 8 and 11 focus on automated testing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exceptions and Semantic Errors\n",
    "\n",
    "\"Exceptions are errors we know about\" (Rother, Chap 2). They result in some sort of error message.  The message contains clues about the problem including the location.  The problem may be related to missing colon, bracket, quotation, etc from the preceeding line.  Commenting out lines of code can be useful to identifying a probem.  In Python, many errors can be caused by incorrect indentation.  Using the `try`... `except` construct, programmers can react to specific situations such as incorrect user input.  It is only recomended when the error is known and predictable.  For example, the following code instructs a user to input a numeric date and if the user does not, it provides additional opportunities for the correct input.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What date would you like to see the APOD? (yyyy-mm-dd) 20-02-02\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-2-8130285cbcc7>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-8130285cbcc7>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    return date_obj\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "date_format = '%Y-%m-%d'\n",
    "date_string = input('What date would you like to see the APOD? (yyyy-mm-dd) ')\n",
    "try:\n",
    "    date_obj = datetime.datetime.strptime(date_string,date_format)\n",
    "    return date_obj\n",
    "except ValueError:\n",
    "    print('You did not enter a valid date.  Please try again.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic errors occur when the program does something different then the programmer planned and does not result in an error message.  This can occur both to individual programmers and to teams.  In a team environment, it is important to precisely describe the input and expected output to avoid missunderstandings that can occur when many individuals with differing perspectives work on the same project.  Finding the error is the starting point for resolving the cause.  Improving code readability makes it easier to find defects.  Many semantic errors require deduction to find the defect.  In the following example of a semantic error, the program should print a message if x is greater then five but it does not.  As you can see, x equals 9 but the comparative operator between X and 5 is incorrect.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is less then 5\n"
     ]
    }
   ],
   "source": [
    "x = 9\n",
    "if x < 5:\n",
    "    print('x is greater than 5')\n",
    "else:\n",
    "    print('x is less then 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Automated Tests and Testing Best Practices\n",
    "\n",
    "Automated testing is a program created to test another program. It should\n",
    "\n",
    "- result in a clear answer such as passes or fails\n",
    "- test small units of code at a time\n",
    "- be simple and use specialized testing frameworks such as py.test, unittest, nose, or doctest\n",
    "\n",
    "It is important to note that \"automated testing proves the presence of defects, not their absence\" (Rother chap 8).  For example, it can't determin if you mispelled a string or used the wrong color on a display.  Best Practices encourages the writing of test code before tackling the program itself.  That way it is easier and quicker to test the project program as it is developed.  The test code is written to fail first thereby proving to the programmer that the code makes a difference if the failed test moves to passed.  The test code should be written to test small pieces of the program at a time and be reproducable.  By writing the project program in a way that is easy to test independently, automated testing promotes well-structured code.  \n",
    "\n",
    "Types of automated tests include (Rother chap 11):\n",
    "\n",
    "- Unit Tests: tests small, isolated units of code\n",
    "- Integration Test: tests the collaboration of two or more laarger components.\n",
    "- Acceptance Test:  tests features from a user's perspective\n",
    "- Regression Test:  rerunning tests to make sure previously built features are still working\n",
    "- Performance Test:  tests execution speed, memory usage or other performance metrics\n",
    "- Load Test:  tests performance under high workload, especially for web servers\n",
    "- Stress Test:  tests functionality under advers conditions (failure of components, attacks, etc.)\n",
    "\n",
    "The first four tests are functional and the last three performance related.  \n",
    "\n",
    "The following is an example of tests grouped in one class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F.F                                                                      [100%]\n",
      "================================== FAILURES ===================================\n",
      "_________________________________ test_answer _________________________________\n",
      "\n",
      "    def test_answer():\n",
      ">       assert func(3) == 5\n",
      "E       assert 4 == 5\n",
      "E        +  where 4 = func(3)\n",
      "\n",
      "<ipython-input-42-1a976585eb41>:6: AssertionError\n",
      "_____________________________ TestClass.test_two ______________________________\n",
      "\n",
      "self = <__main__.TestClass object at 0x000001C15E419320>\n",
      "\n",
      "    def test_two(self):\n",
      "        x = \"one attribute but passing two\"\n",
      ">       assert hasattr(x, 'check')\n",
      "E       AssertionError: assert False\n",
      "E        +  where False = hasattr('one attribute but passing two', 'check')\n",
      "\n",
      "<ipython-input-44-0c231e564cf5>:10: AssertionError\n",
      "============================== warnings summary ===============================\n",
      "Anaconda3\\lib\\site-packages\\_pytest\\config\\__init__.py:754\n",
      "  C:\\Users\\monty\\Anaconda3\\lib\\site-packages\\_pytest\\config\\__init__.py:754: PytestWarning: Module already imported so cannot be rewritten: pytest_remotedata\n",
      "    self._mark_plugins_for_rewrite(hook)\n",
      "  C:\\Users\\monty\\Anaconda3\\lib\\site-packages\\_pytest\\config\\__init__.py:754: PytestWarning: Module already imported so cannot be rewritten: pytest_openfiles\n",
      "    self._mark_plugins_for_rewrite(hook)\n",
      "  C:\\Users\\monty\\Anaconda3\\lib\\site-packages\\_pytest\\config\\__init__.py:754: PytestWarning: Module already imported so cannot be rewritten: pytest_doctestplus\n",
      "    self._mark_plugins_for_rewrite(hook)\n",
      "  C:\\Users\\monty\\Anaconda3\\lib\\site-packages\\_pytest\\config\\__init__.py:754: PytestWarning: Module already imported so cannot be rewritten: pytest_arraydiff\n",
      "    self._mark_plugins_for_rewrite(hook)\n",
      "\n",
      "Error Handling & Testing.ipynb:0\n",
      "  C:\\Users\\monty\\Error Handling & Testing.ipynb:0: PytestWarning: cannot collect test class 'Test' because it has a __init__ constructor\n",
      "\n",
      "-- Docs: https://docs.pytest.org/en/latest/warnings.html\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "# content of test_class.py\n",
    "class TestClass(object):\n",
    "    def test_one(self):\n",
    "        x = \"this one\"\n",
    "        assert 'h' in x\n",
    "\n",
    "    def test_two(self):\n",
    "        x = \"one attribute but passing two\"\n",
    "        assert hasattr(x, 'check')\n",
    "    \n",
    "ipytest.run('-qq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Automated testing is not necessary for small projects (less then 100 lines), projects with rapidly changing data (inefficient use of time), or prototypes (development speed is paramount and defects are acceptable).  In the long run, automated testing saves time and makes collaboration easier.  Writing test code prior to implementing the code to be tested became popular with the move toward the Agile project management framework.  The development cycle became:  \n",
    "\n",
    "1. write test function,\n",
    "2. run test to ensure it fails,\n",
    "3. write code,\n",
    "4. run test and ensure it passes,\n",
    "5. edit code and run regression tests, and \n",
    "6. repeat procedure until done.\n",
    "\n",
    "Alternatives to automated testing are manual testing, code reviews, and checklists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Errors or defects happen no matter how experienced the programmer.  It is important to understand methods for resolving defects.  Best Practices encourage automated testing.  Python has libraries to aid in the writing code for testing.  If automated testing is not used, there are other methods to verify and validate programs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
